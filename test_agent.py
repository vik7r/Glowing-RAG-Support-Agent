#!/usr/bin/env python3
"""
RAG Agentic Support Agent - Test & Demo Script
Run this to test the agent without running the full server
"""

import os
import json
from dotenv import load_dotenv
from pathlib import Path

# Load environment variables
load_dotenv()

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  RAG AGENTIC SUPPORT AGENT - LOCAL TEST                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# ============================================================================
# STEP 1: Check Environment
# ============================================================================
print("\nğŸ“‹ Checking configuration...\n")

required_keys = ["OPENAI_API_KEY", "PINECONE_API_KEY"]
missing = []

for key in required_keys:
    value = os.getenv(key)
    if value:
        masked = value[:10] + "..." + value[-4:] if len(value) > 14 else "***"
        print(f"  âœ“ {key}: {masked}")
    else:
        print(f"  âœ— {key}: NOT SET")
        missing.append(key)

if missing:
    print(f"\nâŒ Missing required keys: {', '.join(missing)}")
    print("   Please create .env file with your API keys")
    exit(1)

print("\nâœ… All required keys present!")

# ============================================================================
# STEP 2: Initialize Components
# ============================================================================
print("\nğŸ”§ Initializing components...\n")

try:
    from langchain_openai import ChatOpenAI, OpenAIEmbeddings
    print("  âœ“ LangChain & OpenAI")
except Exception as e:
    print(f"  âœ— LangChain error: {e}")
    print("    Run: pip install langchain langchain-openai")
    exit(1)

try:
    from pinecone import Pinecone as PineconeClient
    print("  âœ“ Pinecone")
except Exception as e:
    print(f"  âœ— Pinecone error: {e}")
    print("    Run: pip install pinecone-client")
    exit(1)

try:
    from langchain_community.tools.tavily_search import TavilySearchResults
    print("  âœ“ Tavily Web Search")
except:
    print("  âš  Tavily (optional)")

# ============================================================================
# STEP 3: Test LLM Connection
# ============================================================================
print("\nğŸ§  Testing LLM connection...\n")

try:
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    response = llm.invoke("Say 'RAG Agent Ready' and nothing else")
    print(f"  âœ“ LLM Response: {response.content}")
except Exception as e:
    print(f"  âœ— LLM Error: {e}")
    exit(1)

# ============================================================================
# STEP 4: Test Embeddings
# ============================================================================
print("\nğŸ“Š Testing embeddings...\n")

try:
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    embedding = embeddings.embed_query("test query")
    print(f"  âœ“ Embedding dimension: {len(embedding)}")
except Exception as e:
    print(f"  âœ— Embedding Error: {e}")
    exit(1)

# ============================================================================
# STEP 5: Test Pinecone Connection
# ============================================================================
print("\nğŸ“ Testing Pinecone connection...\n")

try:
    pc = PineconeClient(api_key=os.getenv("PINECONE_API_KEY"))
    indexes = pc.list_indexes().names()
    print(f"  âœ“ Connected to Pinecone")
    print(f"  âœ“ Available indexes: {indexes if indexes else 'None yet'}")
except Exception as e:
    print(f"  âœ— Pinecone Error: {e}")

# ============================================================================
# STEP 6: Test Agentic Reasoning
# ============================================================================
print("\nğŸ¤– Testing agent reasoning...\n")

class TestAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    def route_query(self, question: str) -> str:
        """Test query routing"""
        routing_prompt = f"""
        Determine which tool to use: "{question}"
        Options: knowledge_base, web_search, direct_answer
        Respond with ONE tool name only.
        """
        response = self.llm.invoke(routing_prompt)
        return response.content.strip()
    
    def grade_documents(self, question: str, context: str) -> bool:
        """Test document grading"""
        grade_prompt = f"""
        Question: {question}
        Context: {context[:200]}...
        Is this relevant? Yes or No only.
        """
        response = self.llm.invoke(grade_prompt)
        return "yes" in response.content.lower()

agent = TestAgent()

# Test 1: Query Routing
test_queries = [
    "How do I reset my password?",
    "What's the latest AI news?",
    "Tell me about your company"
]

for query in test_queries:
    tool = agent.route_query(query)
    print(f"  Query: '{query}'")
    print(f"  â†’ Routed to: {tool}\n")

# Test 2: Document Grading
test_context = """
Password Reset Process:
1. Click 'Forgot Password' on login page
2. Enter your email address
3. Check your email for reset link
4. Click the link and create new password
5. Log in with new password
"""

test_question = "How do I reset my password?"
is_relevant = agent.grade_documents(test_question, test_context)
print(f"  Context relevance check: {'âœ“ Relevant' if is_relevant else 'âœ— Not relevant'}\n")

# ============================================================================
# STEP 7: Demo Sample Response
# ============================================================================
print("\nğŸ’¬ Demo: Generating sample response...\n")

sample_response = llm.invoke("""
You are a helpful support agent. Answer briefly:
"What features does your RAG support agent have?"
Keep response to 2-3 sentences.
""")

print(f"  Sample Response:\n  {sample_response.content}\n")

# ============================================================================
# STEP 8: Summary & Next Steps
# ============================================================================
print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
print("â•‘                    âœ… ALL TESTS PASSED                     â•‘")
print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

print("""
ğŸ“š YOUR SYSTEM IS READY!

Next Steps:

1ï¸âƒ£  START THE SERVER
    python backend.py
    
    Server will run at: http://localhost:8000
    API Docs at: http://localhost:8000/docs

2ï¸âƒ£  OPEN THE WEB INTERFACE
    Open 'index.html' in your browser
    (Or create an HTML file with the provided code)

3ï¸âƒ£  UPLOAD YOUR DOCUMENTS
    - Click the upload area in the dashboard
    - Add PDF or TXT files with your support docs
    - Files will be automatically indexed

4ï¸âƒ£  START ASKING QUESTIONS
    Type your support questions in the chat
    Agent will retrieve relevant docs and respond

5ï¸âƒ£  MONITOR CONVERSATION
    - View retrieved sources on the right
    - See reasoning steps
    - Conversation history saved automatically

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ QUICK COMMANDS:

  # Run the backend server
  python backend.py

  # Test API with curl
  curl -X POST http://localhost:8000/query \\
    -H "Content-Type: application/json" \\
    -d '{"question": "Help me with..."}' 

  # Check API docs
  open http://localhost:8000/docs

  # Deploy with Docker
  docker-compose up -d

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ API ENDPOINTS:

  POST   /query                    - Ask a question
  POST   /upload-documents         - Upload PDF/TXT files
  GET    /conversations/{id}       - Get conversation history
  GET    /kb-status               - Check knowledge base status
  DELETE /conversations/{id}       - Delete conversation
  GET    /health                  - Health check
  GET    /docs                    - API documentation

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Questions? Check:
  - SETUP_GUIDE.md for detailed installation
  - backend.py for API implementation
  - index.html for web interface code

Enjoy! ğŸ‰
""")
